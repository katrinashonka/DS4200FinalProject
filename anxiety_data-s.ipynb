{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "900b7e5c",
   "metadata": {},
   "source": [
    "# Analyzing Panic Attack Data: Lifestyle Influences, Potenital Triggers, and Symptoms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2b0a86",
   "metadata": {},
   "source": [
    "Gavin Kornitsky, Massimo Prag, Katrina Shonka, Sarah Hudson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347a6802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948d6891",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('panic_attack_dataset.csv')\n",
    "pd.set_option('display.max_rows', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e399e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e36a109",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Medical_History'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c72772",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "missing_vals = df.isnull().sum()\n",
    "missing_vals # quicker than manually checking df for them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95c7f33",
   "metadata": {},
   "source": [
    "the only column with missing values is Medical_History, and the missing values for that column just mean \n",
    "that those people dont have prexisting conditions, so we will be keeping those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652eff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical data to numerical (Yes/No -> 1/0)\n",
    "yes_no = [\"Sweating\", \"Shortness_of_Breath\", \"Dizziness\", \"Trembling\", \"Smoking\", \"Therapy\", \"Chest_Pain\", \"Medication\"]\n",
    "df[yes_no] = df[yes_no].applymap(lambda x: 1 if x ==\"Yes\" else 0) # assigns 1s to yes val and 0 to no\n",
    "df[yes_no]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dcc1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing non-binary individuals, making male=1, female=0\n",
    "df = df[df[\"Gender\"] != \"Non-binary\"].copy()\n",
    "df.loc[:, \"Gender\"] = df[\"Gender\"].map({\"Female\": 0, \"Male\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c42758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking to see if gender is correctly mapped\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118d3baa",
   "metadata": {},
   "source": [
    "### Standardizing the data\n",
    "for numerical columns. not every numerical column needs to be standardized though\n",
    "\n",
    "Columns where standardization is not neccessary:\n",
    "- Age: Standardization would make it harder to understand, its unneccesary\n",
    "- Panic_Attack_Frequency: its a count of attack per month, standardization would just complicate an easy stat\n",
    "- Duration_Minutes: time in mins should be in raw format\n",
    "\n",
    "Columns that need standardization:\n",
    "- Heart_Rate: Can vary from 60-180 bpm, might dominate some smaller scale features\n",
    "- Caffeine_Intake: smaller values, so it will benefit from standardization if for ex we are comparing heart rate to sleep\n",
    "- Exercise_Frequency: weekly count (0-7)\n",
    "- Sleep_Hours: varies between 3-10 hours so standardizing will help for comparing to caffeine and heart rate \n",
    "- Alcohol_Consumption: this one is so varied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f520d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing\n",
    "numerical = [\"Heart_Rate\", \"Caffeine_Intake\", \"Exercise_Frequency\", \"Sleep_Hours\", \"Alcohol_Consumption\"]\n",
    "# dtype is int64, but pandas needs it as float64 for StanardScaler\n",
    "df[numerical] = df[numerical].astype(\"float64\")\n",
    "\n",
    "# standardization\n",
    "scaler = StandardScaler()\n",
    "df[numerical] = scaler.fit_transform(df[numerical])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036611ed",
   "metadata": {},
   "source": [
    "### Feature Engineering: Panic Severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d3c50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for classifying panic severity\n",
    "def panic_severity(score):\n",
    "    if score <=3:\n",
    "        return \"Low\"\n",
    "    elif 4 <= score <= 6:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"High\"\n",
    "\n",
    "# applying function to df\n",
    "df.loc[:, \"Panic_Severity\"] = df[\"Panic_Score\"].apply(panic_severity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e733777",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f4c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final cleaned and preprocessed dataset :)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa355c5f",
   "metadata": {},
   "source": [
    "### First Visualization: Sankey Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea1ecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sankey diagram functions in code block adapted from lecture notes in DS3500 course\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "# pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "def _code_mapping(df, src, targ):\n",
    "    \"\"\" Map labels in src and targ columns to integers \"\"\"\n",
    "    # Get distinct labels\n",
    "    labels = sorted(list(set(list(df[src]) + list(df[targ]))))\n",
    "\n",
    "    # Get integer codes\n",
    "    codes = list(range(len(labels)))\n",
    "\n",
    "    # Create label to code mapping\n",
    "    lc_map = dict(zip(labels, codes))\n",
    "\n",
    "    # Substitute names for codes in dataframe\n",
    "    df = df.replace({src: lc_map, targ: lc_map})\n",
    "    return df, labels\n",
    "\n",
    "\n",
    "def make_sankey(df, src, targ, vals=None, **kwargs):\n",
    "    \"\"\" Generate a sankey diagram\n",
    "    df - Dataframe\n",
    "    src - Source column\n",
    "    targ - Target column\n",
    "    vals - Values column (optional)\n",
    "    optional params: pad, thickness, line_color, line_width \"\"\"\n",
    "\n",
    "    if vals:\n",
    "        values = df[vals]\n",
    "    else:\n",
    "        values = [1] * len(df[src])  # all 1\n",
    "\n",
    "    df, labels = _code_mapping(df, src, targ)\n",
    "    link = {'source': df[src], 'target': df[targ], 'value': values}\n",
    "\n",
    "    pad = kwargs.get('pad', 50)\n",
    "    thickness = kwargs.get('thickness', 50)\n",
    "    line_color = kwargs.get('line_color', 'black')\n",
    "    line_width = kwargs.get('line_width', 1)\n",
    "\n",
    "    node = {'label': labels, 'pad': pad, 'thickness': thickness, 'line': {'color': line_color, 'width': line_width}}\n",
    "    sk = go.Sankey(link=link, node=node)\n",
    "    fig = go.Figure(sk)\n",
    "\n",
    "    # pixels !\n",
    "    width = kwargs.get('width', 800)\n",
    "    height = kwargs.get('height', 400)\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=width,\n",
    "        height=height)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def show_sankey(df, src, targ, vals=None, **kwargs):\n",
    "    fig = make_sankey(df, src, targ, vals, **kwargs)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c33f44f",
   "metadata": {},
   "source": [
    "### Grouped Bar Chart for Effects of Therapy and Medication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fa7de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "# Create Therapy_Status and Medication_Status columns for labeling purposes using .apply()\n",
    "df['Therapy_Status'] = df['Therapy'].apply(lambda x: 'Therapy' if x == 1 else 'No Therapy')\n",
    "df['Medication_Status'] = df['Medication'].apply(lambda x: 'Medication' if x == 1 else 'No Medication')\n",
    "\n",
    "# Create a combined Therapy/Medication status column\n",
    "df['Status'] = df['Therapy_Status'] + ' & ' + df['Medication_Status']\n",
    "\n",
    "# Group by and count each combined therapy/medication status and panic severity category\n",
    "count_df = df.groupby(['Status', 'Panic_Severity']).size().reset_index(name='Count')\n",
    "\n",
    "# Specify the order of Panic_Severity categories (x-axis)\n",
    "severity_order = ['Low', 'Medium', 'High']\n",
    "\n",
    "# Specify the order of Status categories (subplots)\n",
    "status_order = ['No Therapy & No Medication', 'No Therapy & Medication', \n",
    "                'Therapy & No Medication', 'Therapy & Medication']\n",
    "\n",
    "# Create the grouped bar chart with severity on the x-axis\n",
    "chart = alt.Chart(count_df).mark_bar(color='blue').encode(\n",
    "    x=alt.X('Panic_Severity:N', title='Panic Severity', sort=severity_order),\n",
    "    y=alt.Y('Count:Q', title='Count of Panic Severity'),\n",
    "    \n",
    "\n",
    "    # Ensure the subplots follow the specified order\n",
    "    column=alt.Column('Status:N', title='Therapy and Medication Status', sort=status_order)  \n",
    ").properties(\n",
    "    width=150,  \n",
    "    height=400\n",
    ").interactive()\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66536eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "symptom_df = df[['Sweating', 'Shortness_of_Breath', 'Dizziness',\n",
    "       'Chest_Pain', 'Trembling']]\n",
    "\n",
    "symptom_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c94f256",
   "metadata": {},
   "source": [
    "### Creation of CSV for Stacked Bar Chart for Proportions of Yes/No for Each Symptom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e945930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "symptom_df = df[['Sweating', 'Shortness_of_Breath', 'Dizziness',\n",
    "       'Chest_Pain', 'Trembling']]\n",
    "\n",
    "# Flatten the dataset into (symptom, response) pairs\n",
    "symptom_responses = [(col, response) for col in symptom_df.columns for response in symptom_df[col]]\n",
    "\n",
    "# Count occurrences of each (symptom, response) pair\n",
    "response_counts = Counter(symptom_responses)\n",
    "\n",
    "\n",
    "# Convert to DataFrame\n",
    "symptom_data = pd.DataFrame(response_counts.items(), columns=[\"Symptom - Response\", \"Count\"])\n",
    "symptom_data[\"Symptom - Response\"] = symptom_data[\"Symptom - Response\"].apply(lambda x: f\"{x[0]} - {x[1]}\")\n",
    "\n",
    "# Sort and display the final DataFrame\n",
    "symptom_data = symptom_data.sort_values(by=\"Symptom - Response\").reset_index(drop=True)\n",
    "print(symptom_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
