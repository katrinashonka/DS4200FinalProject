{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "900b7e5c",
   "metadata": {},
   "source": [
    "# Analyzing Panic Attack Data: Lifestyle Influences, Potenital Triggers, and Symptoms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2b0a86",
   "metadata": {},
   "source": [
    "Gavin Kornitsky, Massimo Prag, Katrina Shonka, Sarah Hudson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347a6802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948d6891",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('panic_attack_dataset.csv')\n",
    "pd.set_option('display.max_rows', None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c72772",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "missing_vals = df.isnull().sum()\n",
    "missing_vals # quicker than manually checking df for them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95c7f33",
   "metadata": {},
   "source": [
    "the only column with missing values is Medical_History, and the missing values for that column just mean \n",
    "that those people dont have prexisting conditions, so we will be keeping those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652eff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical data to numerical (Yes/No -> 1/0)\n",
    "yes_no = [\"Sweating\", \"Shortness_of_Breath\", \"Dizziness\", \"Trembling\", \"Smoking\", \"Therapy\", \"Medication\"]\n",
    "df[yes_no] = df[yes_no].map(lambda x: 1 if x ==\"Yes\" else 0) # assigns 1s to yes val and 0 to no\n",
    "df[yes_no]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dcc1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing non-binary individuals, making male=1, female=0\n",
    "df = df[df[\"Gender\"] != \"Non-binary\"].copy()\n",
    "df.loc[:, \"Gender\"] = df[\"Gender\"].map({\"Female\": 0, \"Male\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c42758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking to see if gender is correctly mapped\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118d3baa",
   "metadata": {},
   "source": [
    "### Standardizing the data\n",
    "for numerical columns. not every numerical column needs to be standardized though\n",
    "\n",
    "Columns where standardization is not neccessary:\n",
    "- Age: Standardization would make it harder to understand, its unneccesary\n",
    "- Panic_Attack_Frequency: its a count of attack per month, standardization would just complicate an easy stat\n",
    "- Duration_Minutes: time in mins should be in raw format\n",
    "\n",
    "Columns that need standardization:\n",
    "- Heart_Rate: Can vary from 60-180 bpm, might dominate some smaller scale features\n",
    "- Caffeine_Intake: smaller values, so it will benefit from standardization if for ex we are comparing heart rate to sleep\n",
    "- Exercise_Frequency: weekly count (0-7)\n",
    "- Sleep_Hours: varies between 3-10 hours so standardizing will help for comparing to caffeine and heart rate \n",
    "- Alcohol_Consumption: this one is so varied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f520d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing\n",
    "numerical = [\"Heart_Rate\", \"Caffeine_Intake\", \"Exercise_Frequency\", \"Sleep_Hours\", \"Alcohol_Consumption\"]\n",
    "# dtype is int64, but pandas needs it as float64 for StanardScaler\n",
    "df[numerical] = df[numerical].astype(\"float64\")\n",
    "\n",
    "# standardization\n",
    "scaler = StandardScaler()\n",
    "df[numerical] = scaler.fit_transform(df[numerical])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036611ed",
   "metadata": {},
   "source": [
    "### Feature Engineering: Panic Severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d3c50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for classifying panic severity\n",
    "def panic_severity(score):\n",
    "    if score <=3:\n",
    "        return \"Low\"\n",
    "    elif 4 <= score <= 6:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"High\"\n",
    "\n",
    "# applying function to df\n",
    "df.loc[:, \"Panic_Severity\"] = df[\"Panic_Score\"].apply(panic_severity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e733777",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f4c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final cleaned and preprocessed dataset :)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
