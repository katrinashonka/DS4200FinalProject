{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "900b7e5c",
   "metadata": {},
   "source": [
    "# Analyzing Panic Attack Data: Lifestyle Influences, Potenital Triggers, and Symptoms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2b0a86",
   "metadata": {},
   "source": [
    "Gavin Kornitsky, Massimo Prag, Katrina Shonka, Sarah Hudson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347a6802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948d6891",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('panic_attack_dataset.csv')\n",
    "pd.set_option('display.max_rows', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c72772",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "missing_vals = df.isnull().sum()\n",
    "missing_vals # quicker than manually checking df for them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95c7f33",
   "metadata": {},
   "source": [
    "the only column with missing values is Medical_History, and the missing values for that column just mean \n",
    "that those people dont have prexisting conditions, so we will be keeping those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652eff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical data to numerical (Yes/No -> 1/0)\n",
    "yes_no = [\"Sweating\", \"Shortness_of_Breath\", \"Dizziness\", \"Trembling\", \"Smoking\", \"Therapy\", \"Medication\"]\n",
    "df[yes_no] = df[yes_no].applymap(lambda x: 1 if x ==\"Yes\" else 0) # assigns 1s to yes val and 0 to no\n",
    "df[yes_no]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dcc1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing non-binary individuals, making male=1, female=0\n",
    "df = df[df[\"Gender\"] != \"Non-binary\"].copy()\n",
    "df.loc[:, \"Gender\"] = df[\"Gender\"].map({\"Female\": 0, \"Male\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c42758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking to see if gender is correctly mapped\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118d3baa",
   "metadata": {},
   "source": [
    "### Standardizing the data\n",
    "for numerical columns. not every numerical column needs to be standardized though\n",
    "\n",
    "Columns where standardization is not neccessary:\n",
    "- Age: Standardization would make it harder to understand, its unneccesary\n",
    "- Panic_Attack_Frequency: its a count of attack per month, standardization would just complicate an easy stat\n",
    "- Duration_Minutes: time in mins should be in raw format\n",
    "\n",
    "Columns that need standardization:\n",
    "- Heart_Rate: Can vary from 60-180 bpm, might dominate some smaller scale features\n",
    "- Caffeine_Intake: smaller values, so it will benefit from standardization if for ex we are comparing heart rate to sleep\n",
    "- Exercise_Frequency: weekly count (0-7)\n",
    "- Sleep_Hours: varies between 3-10 hours so standardizing will help for comparing to caffeine and heart rate \n",
    "- Alcohol_Consumption: this one is so varied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f520d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing\n",
    "numerical = [\"Heart_Rate\", \"Caffeine_Intake\", \"Exercise_Frequency\", \"Sleep_Hours\", \"Alcohol_Consumption\", \"Chest_Pain\"]\n",
    "# dtype is int64, but pandas needs it as float64\n",
    "# df[numerical] = df[numerical].astype(\"float64\")\n",
    "numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036611ed",
   "metadata": {},
   "source": [
    "### Feature Engineering: Panic Severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d3c50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for classifying panic severity\n",
    "def panic_severity(score):\n",
    "    if score <=3:\n",
    "        return \"Low\"\n",
    "    elif 4 <= score <= 6:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"High\"\n",
    "\n",
    "# applying function to df\n",
    "df.loc[:, \"Panic_Severity\"] = df[\"Panic_Score\"].apply(panic_severity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e733777",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f4c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final cleaned and preprocessed dataset :)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeef2a8",
   "metadata": {},
   "source": [
    "## Making Sankey Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe32739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "def _code_mapping(df, src, targ):\n",
    "    \"\"\" Map labels in src and targ columns to integers \"\"\"\n",
    "    labels = sorted(list(set(list(df[src]) + list(df[targ]))))\n",
    "    codes = list(range(len(labels)))\n",
    "    lc_map = dict(zip(labels, codes))\n",
    "    df = df.replace({src: lc_map, targ: lc_map})\n",
    "    return df, labels\n",
    "\n",
    "def make_sankey(df, src, targ, vals=None, color_col=None, color_map=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Generate a Sankey diagram with optional link coloring by color_col + color_map.\n",
    "    \n",
    "    df       : DataFrame (already grouped or melted as needed)\n",
    "    src      : name of source column\n",
    "    targ     : name of target column\n",
    "    vals     : name of values column (e.g. 'count'), or None\n",
    "    color_col: name of column that determines link colors (e.g. 'Panic_Severity')\n",
    "    color_map: dict from color_col values to a color string (e.g. {\"Low\": \"green\", \"High\": \"red\"})\n",
    "    kwargs   : additional Sankey styling parameters (pad, thickness, line_color, line_width, etc.)\n",
    "    \"\"\"\n",
    "    # Build the link values\n",
    "    if vals is not None:\n",
    "        values = df[vals]\n",
    "    else:\n",
    "        values = [1]*len(df[src])\n",
    "\n",
    "    # Convert source/target text to integer codes\n",
    "    df_for_sankey = df.copy()\n",
    "    df_for_sankey, labels = _code_mapping(df_for_sankey, src, targ)\n",
    "\n",
    "    # Build link dictionary\n",
    "    link = {\n",
    "        'source': df_for_sankey[src],\n",
    "        'target': df_for_sankey[targ],\n",
    "        'value': values\n",
    "    }\n",
    "\n",
    "    if color_col and color_map:\n",
    "        link_colors = []\n",
    "        for i, row in df_for_sankey.iterrows():\n",
    "            severity = row[color_col]  # e.g. \"Low\", \"Medium\", \"High\"\n",
    "            link_colors.append(color_map.get(severity, \"gray\"))\n",
    "        link['color'] = link_colors  # set link colors\n",
    " \n",
    "    pad = kwargs.get('pad', 50)\n",
    "    thickness = kwargs.get('thickness', 50)\n",
    "    line_color = kwargs.get('line_color', 'black')\n",
    "    line_width = kwargs.get('line_width', 1)\n",
    "    node = {\n",
    "        'label': labels,\n",
    "        'pad': pad,\n",
    "        'thickness': thickness,\n",
    "        'line': {'color': line_color, 'width': line_width}\n",
    "    }\n",
    "\n",
    "    sk = go.Sankey(link=link, node=node)\n",
    "    fig = go.Figure(sk)\n",
    "\n",
    "    width = kwargs.get('width', 800)\n",
    "    height = kwargs.get('height', 400)\n",
    "    fig.update_layout(autosize=False, width=width, height=height)\n",
    "    return fig\n",
    "\n",
    "def show_sankey(df, src, targ, vals=None, color_col=None, color_map=None, **kwargs):\n",
    "    fig = make_sankey(df, src, targ, vals, color_col=color_col, color_map=color_map, **kwargs)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "symptom_cols = [\"Sweating\", \"Dizziness\", \"Chest_Pain\", \"Shortness_of_Breath\"]\n",
    "\n",
    "\n",
    "for col in symptom_cols:\n",
    "    df[col] = df[col].map({1: \"Yes\", 0: \"No\"}).fillna(df[col]) \n",
    "\n",
    "df_melt = pd.melt(\n",
    "    df,\n",
    "    id_vars=[\"Trigger\", \"Panic_Severity\"],\n",
    "    value_vars=symptom_cols,\n",
    "    var_name=\"Symptom\",\n",
    "    value_name=\"HasSymptom\"\n",
    ")\n",
    "df_melt = df_melt[df_melt[\"HasSymptom\"] == \"Yes\"]\n",
    "\n",
    "\n",
    "df_grouped = df_melt.groupby([\"Trigger\", \"Symptom\", \"Panic_Severity\"]).size().reset_index(name=\"count\")\n",
    "\n",
    "df_grouped.head()\n",
    "\n",
    "color_map = {\n",
    "    \"Low\":   \"rgba(0, 128, 0, 0.4)\",       \n",
    "    \"Medium\":\"rgba(255, 165, 0, 0.4)\",     \n",
    "    \"High\":  \"rgba(255, 0, 0, 0.4)\"       \n",
    "}\n",
    "\n",
    "\n",
    "fig = make_sankey(\n",
    "    df_grouped,\n",
    "    src=\"Trigger\",\n",
    "    targ=\"Symptom\",\n",
    "    vals=\"count\",\n",
    "    color_col=\"Panic_Severity\",\n",
    "    color_map=color_map,\n",
    "    width=1000,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
